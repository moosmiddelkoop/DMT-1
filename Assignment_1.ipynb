{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Techniques\n",
    "## Assignment 1\n",
    "\n",
    "### Group 98: Moos Middelkoop, Willem Huijzer, Max Feucht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1A: Exploratory Data Analysis\n",
    "\n",
    "Start with exploring the raw data that is available:\n",
    "- Notice all sorts of properties of the dataset: how many records are there, how many\n",
    "attributes, what kinds of attributes are there, ranges of values, distribution of values,\n",
    "relationships between attributes, missing values, and so on. A table is often a suitable\n",
    "way of showing such properties of a dataset. Notice if something is interesting (to you,\n",
    "or in general), make sure you write it down if you find something worth mentioning. <br><br>\n",
    "- Make various plots of the data. Is there something interesting worth reporting? Re-\n",
    "port the figures, discuss what is in them. What meaning do those bars, lines, dots, etc.\n",
    "convey? Please select essential and interesting plots for discussion, as you have limited\n",
    "space for reporting your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1B: Data Cleaning\n",
    "\n",
    "As the insights from Task 1A will have shown, the dataset you analyze contains quite some\n",
    "noise. Values are sometimes missing, and extreme or incorrect values are seen that are likely\n",
    "outliers you may want to remove from the dataset. We will clean the dataset in two steps:\n",
    "- Apply an approach to remove extreme and incorrect values from your dataset. Describe\n",
    "what your approach is, why you consider that to be a good approach, and describe what\n",
    "the result of applying the approach is. <br><br>\n",
    "- Impute the missing values using two different approaches. Describe the approaches\n",
    "and study the impact of applying them to your data. Argue which one of the two ap-\n",
    "proaches would be most suitable and select that one to form your cleaned dataset. Also\n",
    "base yourself on scientific literature for making your choice.\n",
    "Advanced: The advanced dataset contains a number of time series, select approaches to im-\n",
    "pute missing values that are logical for such time series. Also consider what to do with pro-\n",
    "longed periods of missing data in a time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Code Here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Task 1C: Feature Engineering \n",
    "\n",
    "While we now have a clean dataset, we can still take one step before we move to classification\n",
    "that can in the end help to improve performance, namely feature engineering. As discussed\n",
    "during the lectures, feature engineering is a creative process and can involve for example the\n",
    "transformation of values (e.g. take the log of values given a certain distribution of values) or combining multiple features (e.g. two features that are more valuable combined than the two\n",
    "separate values). Think of a creative feature engineering approach for your dataset, describe\n",
    "it, and apply it. Report on why you think this is a useful enrichment of your dataset. <br>\n",
    "\n",
    "Advanced: Essentially there are two approaches you can consider to create a predictive model\n",
    "using this dataset (which we will do in the next part of this assignment): (1) use a machine\n",
    "learning approach that can deal with temporal data (e.g. ARIMA, recurrent neural networks)\n",
    "or you can try to aggregate the history somehow to create attributes that can be used in a\n",
    "more common machine learning approach (e.g. SVM, decision tree). For instance, you use\n",
    "the average mood during the last five days as a predictor. Ample literature is present in the\n",
    "area of temporal data mining that describes how such a transformation can be made. For\n",
    "the feature engineering, you are going to focus on such a transformation in this part of the\n",
    "assignment. This is illustrated in Figure 1.\n",
    "In the end, we end up with a dataset with a number of training instances per patient (as\n",
    "you have a number of time points for which you can train), i.e. an instance that concerns\n",
    "the mood at t=1, t=2, etc. Of course it depends on your choice of the history you consider\n",
    "relevant from what time point you can start predicting (if you use a windows of 5 days of\n",
    "history to create attributes you cannot create training instances before the 6th day). To come\n",
    "to this dataset, you need to:\n",
    "1. Define attributes that aggregate the history, draw inspiration from the field of temporal\n",
    "data mining.\n",
    "2. Define the target by averaging the mood over the entire day.\n",
    "3. Create an instance-based dataset as described in Figure 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Code Here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2A: Application of Classification Algorithms.\n",
    "\n",
    "Identify the target (i.e. the class you want to predict) for your dataset. In case you use the\n",
    "dataset we collected you are free to choose whatever you like. Split up your data in a train\n",
    "and test set and apply two classification algorithms, at least one of them should have been\n",
    "discussed during the lectures. Optimize the hyperparameters of the approaches. Measure\n",
    "and discuss the performance using a performance metric and argue why that is a suitable\n",
    "metric. Describe all steps in your process clearly and fully to make sure it is reproducible.<br>\n",
    "Advanced: For the advanced assignment you go through the same steps (and shape it into\n",
    "a classification problem for predicting the mood of the next day), however you are required\n",
    "to use two different types of classification algorithms, namely one that uses the dataset you\n",
    "formed in Task 1C (e.g. using a random forest) and an algorithm that is inherently temporal\n",
    "(e.g. ARIMA, recurrent neural networks). Also consider a good evaluation setup given the\n",
    "nature of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2B: Winning Classification Algorithms\n",
    "\n",
    "Machine learning techniques that are used in Data Mining projects develop quickly these\n",
    "days. One nice way to track these developments is to see which algorithms win competitions\n",
    "on websites such as Kaggle. Your task is to describe the approach of the winner of one of those\n",
    "competitions that focus on a classification tasks. The following sites might serve as starting\n",
    "points: <br>\n",
    "- http://www.kaggle.com/ - DM competitions\n",
    "- https://www.kdd.org/kdd-cup - KDD Cup <br>\n",
    "\n",
    "You should be able to find other relevant competitions by searching the Web.\n",
    "The main goal is that you can demonstrate that you understand a technique that beats other\n",
    "techniques under certain conditions (specified by the task and data at hand). Here’s what\n",
    "we’d like you to include in the report for this task: <br>\n",
    "\n",
    "- A description of the competition: what competition, when was it held, what data they\n",
    "were using, what task(s) they were solving, what evaluation measure(s) they used.\n",
    "- Who was the winner, what technique did they use?\n",
    "- What was the main idea of the winning approach? (Typically this would come from a\n",
    "paper written by the winners.)\n",
    "- What makes the winning approach stand out, or how is it different from standard, or\n",
    "non-winning methods? <br>\n",
    "Particular rules and points to consider:\n",
    "• A suggestion: 1 page should be more than enough for this task.\n",
    "• Needless to say, but for the record, please do not copy and paste from papers. Always\n",
    "cite (properly) the source of the paper you are using."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Association Rules\n",
    "\n",
    "We have seen the APRIORI algorithm during the lecture that targets finding associations in\n",
    "datasets, predicting that an item is likely to be bought given other items that are in the shop-\n",
    "ping basket already. As mentioned during the lecture, many innovations have been made to\n",
    "improve the APRIORI and other methods. One category of improvements involves grouping\n",
    "of products into higher level product categories (e.g. a Pizza Margherita and Pizza Quattro\n",
    "Formaggio are both pizza’s). Find an approach that aims to do this and describe it. Discuss\n",
    "the pros and cons of such an approach.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Numerical Prediction\n",
    "Similar to Task 2A, apply a machine learning algorithm to your dataset, but now focus on pre-\n",
    "dicting a numerical target. Describe similar details as you have for the classification problem.\n",
    "Highlight the differences you see between the two types of prediction tasks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5A: Characteristics of Evaluation Metrics: \n",
    "Consider the following two error measures: mean squared error (MSE) and mean absolute\n",
    "error (MAE).\n",
    "- Write down their corresponding formulae.\n",
    "- Discuss: Why would someone use one and not the other?\n",
    "- Describe an example situation (dataset, problem, algorithm perhaps) where using MSE\n",
    "or MAE would give identical results. Justify your answer (some maths may come handy,\n",
    "but clear explanation is also sufficient)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5B: Impact of Evaluation Metrics\n",
    "\n",
    "Apply the MSE and MAE as evaluation metrics to the numerical prediction problem you have\n",
    "worked on under Task 4. Describe how the model behaves under the different characteristics\n",
    "and describe the implications."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer here"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
